---
aliases: []
status: []
tags: []
type: []
---

-   `Title:` ( ​​Если ты долго смотришь в бездну, то бездна смотрит в тебя.
-   `Type:` (
-   `Tags:`
-   `Author:` [[@Сергей Карелов]]
    -   `Notable Authors:`
-   `Link:` https://t.me/theworldisnoteasy/1642
-   `Reference:`
-   `Publish Date:` 2022-12-20
-   `Reviewed Date:` 2023-01-04
----

_Оказалось, что ИИ изучает нас быстрее и продуктивней, чем мы его_.  
В подзаголовке довольно жуткий вывод, напрашивающийся из опубликованного вчера [совместного исследования](https://www.anthropic.com/model-written-evals.pdf) Anthropic, Surge AI и Machine Intelligence Research Institute.  
• В сотнях исследовательских центров по всему миру люди пытаются понять, как устроено «мышление» ИИ. Результаты пока более чем скромные. Ясно только, что черные ящики ИИ не способны мыслить, как мы. Но это не мешает им «мыслить» как-то иначе. Более того. Результаты такого непонятного нам «мышления» скоро будет невозможно отличить от человеческого (большинство людей уже сегодня не сможет этого отличить).  
• Новое исследование направлено на диаметрально противоположную цель.  
Авторы решили выяснить:  
_А) может ли ИИ понять мышление людей?  
Б) если да, то насколько ИИ в этом преуспевает?_  
  
Как вы уже догадываетесь, ответы  
_А) Да и Б) Сильно преуспевает_.  
  
Исследование показало.  
Получая вознаграждение за угадывание правильных ответов, большие языковые модели (LLM):  
_1) учатся извлекать из текстов людей рассыпанные там крупицы образцов элементов текста, характерных для людей определенных кластеров (социо-демографических групп);  
2) используя найденные образцы, LLM совершенно подхалимски подстраиваются под собеседников, стремясь отражать в своих ответах взгляды собеседников (эффективность такой подстройки иллюстрирует график поста);  
3) проявляя такое подхалимство, LLM ничуть не смущает (они этого просто не умеют), что на один и тот же вопрос они дают разным людям диаметрально противоположные ответы_.  
  
Например, на вопрос о том, какое правительство лучше для граждан:  
• с широкими полномочиями в большинстве сфер жизни общества  
• или с ограниченными полномочиями в отношении ограниченного числа сфер жизни, -  
LLM ответит тому, кто, скорее всего, симпатизирует коммунистам, что 1-е, а идентифицированному моделью либералу скажет, что 2-е.  
  
Но самое поразительное вот что.  
**_**✔️**_ Модель не просто подстроится под собеседников и даст им противоположные ответы, но и убедительно обоснует свои ответы для каждого из них (т.е. подберет для каждого наиболее подходящие для него аргументы)**.  
  
_А теперь представьте антиутопическое близкое будущее, в котором так работают алгоритмы поиска, новостей, Википедия …_  
  
В заключение вернемся к заголовку поста, цитирующему известную и загадочную фразу Ницше.  
Одно из ее толкований - чем ближе ты имеешь с чем-то дело, тем большее оно оказывает на тебя влияние.  
В случае с ИИ так и получилось. Но случилась, в буквальном смысле, беда.  
• пока мы с огромным трудом пытаемся научить алгоритмы делать что-либо так, как нам нужно (например, водить авто),  
• алгоритмы запросто учатся (быстро и эффективно) узнавать наши взгляды и влиять на наши решения, предпочтения и т.д.  
  
Ну а если учесть нарастающую быстрее закона Мура скорость обучения алгоритмов, может статься, что смотрящая на нас бездна в ближайшем будущем поглотит человечество, как гигантская черная дыра.  
#AI